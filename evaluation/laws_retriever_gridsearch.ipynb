{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9241c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Absolute path to your project root (set explicitly if needed)\n",
    "PROJECT_ROOT = \"c:/vscode-projects/legal-rag-project\"\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "# Add to sys.path for module imports\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "    print(\"Added to sys.path:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34fc2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from qdrant_client.models import SparseVector\n",
    "from retrieval import get_qdrant_client, search_with_precomputed_vectors, match_article\n",
    "# Load .pkl dataset\n",
    "with open(\"evaluation\\eval_query_all_embeddings.pkl\", \"rb\") as f:\n",
    "    eval_dset = pickle.load(f)\n",
    "\n",
    "queries = eval_dset[\"queries\"]\n",
    "relevant_articles = eval_dset[\"relevant_articles\"]\n",
    "\n",
    "# Define configs: model -> collection mapping\n",
    "model_configs = [\n",
    "    {\"model_name\": \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\", \"collection_name\": \"qwen-laws-2048-chunks\"},\n",
    "    {\"model_name\": \"jinaai/jina-embeddings-v3\", \"collection_name\": \"jina-laws-2048-chunks\"},\n",
    "    {\"model_name\": \"Alibaba-NLP/gte-multilingual-base\", \"collection_name\": \"gte-laws-2048-chunks\"},\n",
    "    {\"model_name\": \"BAAI/bge-m3\", \"collection_name\": \"bge-laws-2048-chunks\"},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c95b1f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: Alibaba-NLP/gte-Qwen2-1.5B-instruct on collection: qwen-laws-2048-chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:05<00:00, 38.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: jinaai/jina-embeddings-v3 on collection: jina-laws-2048-chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:05<00:00, 39.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: Alibaba-NLP/gte-multilingual-base on collection: gte-laws-2048-chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:04<00:00, 42.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: BAAI/bge-m3 on collection: bge-laws-2048-chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:05<00:00, 34.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Hit@1</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAAI/bge-m3</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alibaba-NLP/gte-Qwen2-1.5B-instruct</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jinaai/jina-embeddings-v3</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alibaba-NLP/gte-multilingual-base</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Hit@1  Hit@5  MAP@5    MRR  NDCG@5\n",
       "3                          BAAI/bge-m3  0.344  0.627  0.441  0.463   0.483\n",
       "0  Alibaba-NLP/gte-Qwen2-1.5B-instruct  0.306  0.636  0.437  0.447   0.482\n",
       "1            jinaai/jina-embeddings-v3  0.297  0.617  0.411  0.433   0.460\n",
       "2    Alibaba-NLP/gte-multilingual-base  0.311  0.589  0.397  0.427   0.442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_k = 5\n",
    "client = get_qdrant_client()\n",
    "VERBOSE = False  # Set to False to suppress debugging prints\n",
    "\n",
    "def compute_metrics(retrieved, relevant, k):\n",
    "    top_k = retrieved[:k]\n",
    "    relevant_set = set((g[\"law_code\"], g[\"law_number\"]) for g in relevant)\n",
    "\n",
    "    correct = [pred for pred in top_k if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set]\n",
    "    precision_at_k = len(correct) / k\n",
    "\n",
    "    hits = 0\n",
    "    ap = 0.0\n",
    "    for i, pred in enumerate(top_k):\n",
    "        if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set:\n",
    "            hits += 1\n",
    "            ap += hits / (i + 1)\n",
    "    map_at_k = ap / len(relevant) if relevant else 0.0\n",
    "\n",
    "    rr = 0.0\n",
    "    for i, pred in enumerate(retrieved):\n",
    "        if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "\n",
    "    dcg = 0.0\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(k, len(relevant)))])\n",
    "    for i, pred in enumerate(top_k):\n",
    "        if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    return precision_at_k, map_at_k, rr, ndcg\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config[\"model_name\"]\n",
    "    collection = config[\"collection_name\"]\n",
    "    embeddings = eval_dset[model_name]\n",
    "\n",
    "    print(f\"\\nEvaluating model: {model_name} on collection: {collection}\")\n",
    "    hit1 = 0\n",
    "    hitk = 0\n",
    "    mapk = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "\n",
    "    for i, query in enumerate(tqdm(queries)):\n",
    "        dense_vec = embeddings[i]\n",
    "        relevant = relevant_articles[i]\n",
    "\n",
    "        try:\n",
    "            res = search_with_precomputed_vectors(\n",
    "                client=client,\n",
    "                collection_name=collection,\n",
    "                top_k=top_k,\n",
    "                retriever_type=\"dense\",\n",
    "                dense_vector=dense_vec\n",
    "            )\n",
    "\n",
    "            retrieved = []\n",
    "            for r in res.points:\n",
    "                payload = r.payload or {}\n",
    "                meta = payload.get(\"metadata\", {}) or {}\n",
    "\n",
    "                law_code = meta.get(\"law_code\")\n",
    "                law_number = meta.get(\"law_number\")\n",
    "\n",
    "                if not law_code or not law_number:\n",
    "                    if VERBOSE:\n",
    "                        print(f\"[WARN] Missing law_code/law_number in result {i}\")\n",
    "                    continue\n",
    "\n",
    "                retrieved.append({\n",
    "                    \"law_code\": law_code,\n",
    "                    \"law_number\": law_number\n",
    "                })\n",
    "\n",
    "            if VERBOSE:\n",
    "                print(f\"\\nQuery {i}: {query}\")\n",
    "                print(f\"→ Retrieved: {len(retrieved)}\")\n",
    "                if retrieved:\n",
    "                    print(\"→ First result:\", retrieved[0])\n",
    "                else:\n",
    "                    print(\"→ No valid retrievals\")\n",
    "\n",
    "            if not retrieved:\n",
    "                continue\n",
    "\n",
    "            p, ap, r_, n = compute_metrics(retrieved, relevant, top_k)\n",
    "\n",
    "            try:\n",
    "                top_hit = next(x for x in retrieved if match_article(x, relevant[0]))\n",
    "                hit1 += int(retrieved.index(top_hit) == 0)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "\n",
    "            hitk += int(p > 0)\n",
    "            mapk.append(ap)\n",
    "            mrr.append(r_)\n",
    "            ndcg.append(n)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[ERROR] Failed on query: {query}\\n{e}\")\n",
    "\n",
    "    total = len(queries)\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"Hit@1\": round(hit1 / total, 3),\n",
    "        f\"Hit@{top_k}\": round(hitk / total, 3),\n",
    "        f\"MAP@{top_k}\": round(np.mean(mapk), 3),\n",
    "        \"MRR\": round(np.mean(mrr), 3),\n",
    "        f\"NDCG@{top_k}\": round(np.mean(ndcg), 3),\n",
    "    })\n",
    "\n",
    "# Optional: Show results table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "display(df.sort_values(\"MRR\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce9dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE (mode: dense)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:05<00:00, 40.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE (mode: hybrid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:03<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE (mode: sparse)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:03<00:00, 60.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>Hit@1</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sparse</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mode  Hit@1  Hit@5  MAP@5    MRR  NDCG@5\n",
       "0   dense  0.344  0.579  0.446  0.453   0.484\n",
       "1  hybrid  0.230  0.512  0.354  0.359   0.396\n",
       "2  sparse  0.072  0.196  0.125  0.125   0.141"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare BGE Dense vs Hybrid (using precomputed sparse vectors)\n",
    "\n",
    "modes = [\"dense\", \"hybrid\"]\n",
    "results_bge = []\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"Evaluating BGE (mode: {mode})\")\n",
    "    hit1 = 0\n",
    "    hitk = 0\n",
    "    mapk = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "\n",
    "    for i, query in enumerate(tqdm(eval_dset[\"queries\"])):\n",
    "        dense = eval_dset[\"BAAI/bge-m3\"][i]\n",
    "        indices = eval_dset[\"bm25_indices\"][i]\n",
    "        values = eval_dset[\"bm25_values\"][i]\n",
    "        relevant = eval_dset[\"relevant_articles\"][i]\n",
    "        sparse_vector = SparseVector(indices=indices, values=values)\n",
    "\n",
    "        try:\n",
    "            res = search_with_precomputed_vectors(\n",
    "                client=client,\n",
    "                collection_name=\"bge-laws-2048-chunks\",\n",
    "                top_k=top_k,\n",
    "                retriever_type=mode,\n",
    "                dense_vector=dense,\n",
    "                sparse_vector=sparse_vector,\n",
    "            )\n",
    "\n",
    "            retrieved = []\n",
    "            for r in res.points:\n",
    "                meta = (r.payload or {}).get(\"metadata\", {})\n",
    "                retrieved.append({\n",
    "                    \"law_code\": meta.get(\"law_code\"),\n",
    "                    \"law_number\": meta.get(\"law_number\"),\n",
    "                })\n",
    "\n",
    "            if not retrieved:\n",
    "                continue\n",
    "\n",
    "            p, ap, r_, n = compute_metrics(retrieved, relevant, top_k)\n",
    "            hit1 += int(p > 0 and retrieved.index([x for x in retrieved if match_article(x, relevant[0])][0]) == 0)\n",
    "            hitk += int(p > 0)\n",
    "            mapk.append(ap)\n",
    "            mrr.append(r_)\n",
    "            ndcg.append(n)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    total = len(eval_dset[\"queries\"])\n",
    "    results_bge.append({\n",
    "        \"mode\": mode,\n",
    "        \"Hit@1\": round(hit1 / total, 3),\n",
    "        f\"Hit@{top_k}\": round(hitk / total, 3),\n",
    "        f\"MAP@{top_k}\": round(np.mean(mapk), 3),\n",
    "        \"MRR\": round(np.mean(mrr), 3),\n",
    "        f\"NDCG@{top_k}\": round(np.mean(ndcg), 3),\n",
    "    })\n",
    "\n",
    "# Add Sparse-only mode for BGE\n",
    "print(\"Evaluating BGE (mode: sparse)\")\n",
    "hit1 = 0\n",
    "hitk = 0\n",
    "mapk = []\n",
    "mrr = []\n",
    "ndcg = []\n",
    "\n",
    "for i, query in enumerate(tqdm(eval_dset[\"queries\"])):\n",
    "    indices = eval_dset[\"bm25_indices\"][i]\n",
    "    values = eval_dset[\"bm25_values\"][i]\n",
    "    relevant = eval_dset[\"relevant_articles\"][i]\n",
    "    sparse_vector = SparseVector(indices=indices, values=values)\n",
    "\n",
    "    try:\n",
    "        res = search_with_precomputed_vectors(\n",
    "            client=client,\n",
    "            collection_name=\"bge-laws-2048-chunks\",\n",
    "            top_k=top_k,\n",
    "            retriever_type=\"sparse\",\n",
    "            sparse_vector=sparse_vector,\n",
    "        )\n",
    "\n",
    "        retrieved = []\n",
    "        for r in res.points:\n",
    "            meta = (r.payload or {}).get(\"metadata\", {})\n",
    "            retrieved.append({\n",
    "                \"law_code\": meta.get(\"law_code\"),\n",
    "                \"law_number\": meta.get(\"law_number\"),\n",
    "            })\n",
    "\n",
    "        if not retrieved:\n",
    "            continue\n",
    "\n",
    "        p, ap, r_, n = compute_metrics(retrieved, relevant, top_k)\n",
    "        hit1 += int(p > 0 and retrieved.index([x for x in retrieved if match_article(x, relevant[0])][0]) == 0)\n",
    "        hitk += int(p > 0)\n",
    "        mapk.append(ap)\n",
    "        mrr.append(r_)\n",
    "        ndcg.append(n)\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "total = len(eval_dset[\"queries\"])\n",
    "results_bge.append({\n",
    "    \"mode\": \"sparse\",\n",
    "    \"Hit@1\": round(hit1 / total, 3),\n",
    "    f\"Hit@{top_k}\": round(hitk / total, 3),\n",
    "    f\"MAP@{top_k}\": round(np.mean(mapk), 3),\n",
    "    \"MRR\": round(np.mean(mrr), 3),\n",
    "    f\"NDCG@{top_k}\": round(np.mean(ndcg), 3),\n",
    "})\n",
    "\n",
    "# Show final results\n",
    "pd.DataFrame(results_bge)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
