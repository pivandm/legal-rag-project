{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9241c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\vscode-projects\\legal-rag-project\n",
      "Added to sys.path: c:/vscode-projects/legal-rag-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Absolute path to your project root (set explicitly if needed)\n",
    "PROJECT_ROOT = \"c:/vscode-projects/legal-rag-project\"\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "# Add to sys.path for module imports\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "    print(\"Added to sys.path:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fc2654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from qdrant_client.models import SparseVector\n",
    "from retrieval import get_qdrant_client, search_with_precomputed_vectors, match_article\n",
    "from logger import get_logger\n",
    "\n",
    "logger = get_logger(\"EVALUATE-LAWS\")\n",
    "# Load .pkl dataset\n",
    "with open(\"evaluation\\eval_query_all_embeddings.pkl\", \"rb\") as f:\n",
    "    eval_dset = pickle.load(f)\n",
    "\n",
    "queries = eval_dset[\"queries\"]\n",
    "relevant_articles = eval_dset[\"relevant_articles\"]\n",
    "\n",
    "# Define configs: model -> collection mapping\n",
    "model_configs = [\n",
    "    {\"model_name\": \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\", \"collection_name\": \"qwen-laws-2048-chunks\"},\n",
    "    {\"model_name\": \"jinaai/jina-embeddings-v3\", \"collection_name\": \"jina-laws-2048-chunks\"},\n",
    "    {\"model_name\": \"Alibaba-NLP/gte-multilingual-base\", \"collection_name\": \"gte-laws-2048-chunks\"},\n",
    "    {\"model_name\": \"BAAI/bge-m3\", \"collection_name\": \"bge-laws-2048-chunks\"},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95b1f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 22:58:47,020 - INFO - EVALUATE-LAWS - Evaluating model: Alibaba-NLP/gte-Qwen2-1.5B-instruct on collection: qwen-laws-2048-chunks\n",
      "Alibaba-NLP/gte-Qwen2-1.5B-instruct | Hit@5 Rate: 0.646 | Recall@5: 0.591: 100%|██████████| 206/206 [00:06<00:00, 33.49it/s]\n",
      "2025-04-21 22:58:53,181 - INFO - EVALUATE-LAWS - Evaluating model: jinaai/jina-embeddings-v3 on collection: jina-laws-2048-chunks\n",
      "jinaai/jina-embeddings-v3 | Hit@5 Rate: 0.626 | Recall@5: 0.579: 100%|██████████| 206/206 [00:04<00:00, 48.74it/s]\n",
      "2025-04-21 22:58:57,412 - INFO - EVALUATE-LAWS - Evaluating model: Alibaba-NLP/gte-multilingual-base on collection: gte-laws-2048-chunks\n",
      "Alibaba-NLP/gte-multilingual-base | Hit@5 Rate: 0.597 | Recall@5: 0.553: 100%|██████████| 206/206 [00:04<00:00, 42.80it/s]\n",
      "2025-04-21 22:59:02,229 - INFO - EVALUATE-LAWS - Evaluating model: BAAI/bge-m3 on collection: bge-laws-2048-chunks\n",
      "BAAI/bge-m3 | Hit@5 Rate: 0.636 | Recall@5: 0.576: 100%|██████████| 206/206 [00:04<00:00, 42.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Hit@1</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAAI/bge-m3</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alibaba-NLP/gte-Qwen2-1.5B-instruct</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jinaai/jina-embeddings-v3</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alibaba-NLP/gte-multilingual-base</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Hit@1  Hit@5  MAP@5    MRR  NDCG@5  \\\n",
       "0                          BAAI/bge-m3  0.350  0.636  0.429  0.470   0.477   \n",
       "1  Alibaba-NLP/gte-Qwen2-1.5B-instruct  0.311  0.646  0.412  0.454   0.467   \n",
       "2            jinaai/jina-embeddings-v3  0.301  0.626  0.408  0.439   0.459   \n",
       "3    Alibaba-NLP/gte-multilingual-base  0.316  0.597  0.401  0.433   0.448   \n",
       "\n",
       "   Recall@5  Precision@5  \n",
       "0     0.576        0.134  \n",
       "1     0.591        0.138  \n",
       "2     0.579        0.132  \n",
       "3     0.553        0.131  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_k = 5\n",
    "client = get_qdrant_client()\n",
    "VERBOSE = False  # Set to True to enable debug logging\n",
    "\n",
    "def compute_metrics(retrieved, relevant, k):\n",
    "    top_k = retrieved[:k]\n",
    "    relevant_set = set((g[\"law_code\"], g[\"law_number\"]) for g in relevant)\n",
    "\n",
    "    correct = [pred for pred in top_k if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set]\n",
    "    precision_at_k = len(correct) / k\n",
    "    recall_at_k = len(correct) / len(relevant) if relevant else 0.0\n",
    "\n",
    "    hits = 0\n",
    "    ap = 0.0\n",
    "    for i, pred in enumerate(top_k):\n",
    "        if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set:\n",
    "            hits += 1\n",
    "            ap += hits / (i + 1)\n",
    "    map_at_k = ap / len(relevant) if relevant else 0.0\n",
    "\n",
    "    rr = 0.0\n",
    "    for i, pred in enumerate(retrieved):\n",
    "        if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "\n",
    "    dcg = 0.0\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(k, len(relevant)))])\n",
    "    for i, pred in enumerate(top_k):\n",
    "        if (pred[\"law_code\"], pred[\"law_number\"]) in relevant_set:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    return precision_at_k, map_at_k, rr, ndcg, recall_at_k\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config[\"model_name\"]\n",
    "    collection = config[\"collection_name\"]\n",
    "    embeddings = eval_dset[model_name]\n",
    "\n",
    "    logger.info(f\"Evaluating model: {model_name} on collection: {collection}\")\n",
    "    hit1 = 0\n",
    "    hitk = 0\n",
    "    failures = 0\n",
    "    pk = []\n",
    "    mapk = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "    recall_values = []\n",
    "    hits = []\n",
    "\n",
    "    progress = tqdm(enumerate(queries), total=len(queries))\n",
    "    total = len(queries)\n",
    "    for i, query in progress:\n",
    "        dense_vec = embeddings[i]\n",
    "        relevant = relevant_articles[i]\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                res = search_with_precomputed_vectors(\n",
    "                    client=client,\n",
    "                    collection_name=collection,\n",
    "                    top_k=top_k,\n",
    "                    retriever_type=\"dense\",\n",
    "                    dense_vector=dense_vec\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[Search Error] Query {i}: {query}\\n{e}\")\n",
    "                failures += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                retrieved = []\n",
    "                for r in res.points:\n",
    "                    payload = r.payload or {}\n",
    "                    meta = payload.get(\"metadata\", {})\n",
    "                    law_code = meta.get(\"law_code\")\n",
    "                    law_number = meta.get(\"law_number\")\n",
    "                    if law_code and law_number:\n",
    "                        retrieved.append({\n",
    "                            \"law_code\": law_code,\n",
    "                            \"law_number\": law_number\n",
    "                        })\n",
    "                seen = set()\n",
    "                deduped = []\n",
    "                for item in retrieved:\n",
    "                    key = (item[\"law_code\"], item[\"law_number\"])\n",
    "                    if key not in seen:\n",
    "                        deduped.append(item)\n",
    "                        seen.add(key)\n",
    "                retrieved = deduped\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[Parsing Error] Query {i}: {query}\\n{e}\")\n",
    "                failures += 1\n",
    "                continue\n",
    "\n",
    "            if not retrieved:\n",
    "                logger.warning(f\"[Empty Result] Query {i}: {query}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                p, ap, r_, n, recall = compute_metrics(retrieved, relevant, top_k)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"[Metric Error] Query {i}: {query}\\n{e}\")\n",
    "                failures += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                top_hit = next(x for x in retrieved if match_article(x, relevant[0]))\n",
    "                hit1 += int(retrieved.index(top_hit) == 0)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"[Hit@1 Index Error] Query {i}: {query}\\n{e}\")\n",
    "            hitk_it = int(p > 0)\n",
    "            hitk += hitk_it\n",
    "            hits.append(hitk_it)\n",
    "            pk.append(p)\n",
    "            mapk.append(ap)\n",
    "            mrr.append(r_)\n",
    "            ndcg.append(n)\n",
    "            recall_values.append(recall)\n",
    "            if hitk_it < recall:\n",
    "                logger.warning(\n",
    "                    f\"[Hit@{top_k} Mismatch] Query {i}: Hit@{top_k} < Recall@{top_k}\\n\"\n",
    "                    f\"Hit@{top_k}: {hitk_it} | Recall@{top_k}: {recall}\\n\"\n",
    "                    f\"Precision@{top_k}: {p}\\n\"\n",
    "                    f\"Query: {query}\\n\"\n",
    "                    f\"Relevant: {relevant}\\n\"\n",
    "                    f\"Retrieved: {retrieved}\"\n",
    "                )\n",
    "            if VERBOSE:\n",
    "                logger.info(\n",
    "                    f\"[Query {i}] P@{top_k}: {p:.3f} | R@{top_k}: {recall:.3f} | AP: {ap:.3f} | RR: {r_:.3f} | NDCG: {n:.3f}\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"[Unknown Error] Query {i}: {query}\\n{e}\")\n",
    "            failures += 1\n",
    "\n",
    "        progress.set_description(\n",
    "            f\"{model_name} | Hit@{top_k} Rate: {hitk/total:.3f} | Recall@{top_k}: {np.mean(recall_values):.3f}\"\n",
    "        )\n",
    "    # print(all(h >= r for h, r in zip(hits, recall_values)))\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"Hit@1\": round(hit1 / total, 3),\n",
    "        f\"Hit@{top_k}\": round(hitk / total, 3),\n",
    "        f\"MAP@{top_k}\": round(np.mean(mapk), 3),\n",
    "        \"MRR\": round(np.mean(mrr), 3),\n",
    "        f\"NDCG@{top_k}\": round(np.mean(ndcg), 3),\n",
    "        f\"Recall@{top_k}\": round(np.mean(recall_values), 3),\n",
    "        f\"Precision@{top_k}\": round(np.mean(pk), 3),\n",
    "    })\n",
    "\n",
    "models_results = pd.DataFrame(results)\n",
    "display(models_results.sort_values(\"MRR\", ascending=False).reset_index(drop=True))\n",
    "models_results.to_csv(\n",
    "    rf\"C:\\vscode-projects\\legal-rag-project\\eval_results\\models_comparison_at{top_k}.csv\", index=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce9dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE (mode: dense)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dense | Hit@5: 0.636 | Recall@5: 0.576: 100%|██████████| 206/206 [00:04<00:00, 47.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE (mode: hybrid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid | Hit@5: 0.553 | Recall@5: 0.504: 100%|██████████| 206/206 [00:04<00:00, 50.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE (mode: sparse)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sparse | Hit@5: 0.214 | Recall@5: 0.193: 100%|██████████| 206/206 [00:03<00:00, 67.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>Hit@1</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sparse</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mode  Hit@1  Hit@5  MAP@5    MRR  NDCG@5  Recall@5  Precision@5\n",
       "0   dense  0.350  0.636  0.429  0.470   0.477     0.576        0.134\n",
       "1  hybrid  0.214  0.553  0.329  0.361   0.382     0.504        0.116\n",
       "2  sparse  0.073  0.214  0.120  0.135   0.142     0.193        0.046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modes = [\"dense\", \"hybrid\", \"sparse\"]\n",
    "results_bge = []\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"Evaluating BGE (mode: {mode})\")\n",
    "    hit1 = 0\n",
    "    hitk = 0\n",
    "    pk = []\n",
    "    mapk = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "    recall_values = []\n",
    "    hits = []\n",
    "\n",
    "    progress = tqdm(enumerate(eval_dset[\"queries\"]), total=len(eval_dset[\"queries\"]))\n",
    "    total = len(eval_dset[\"queries\"])\n",
    "\n",
    "    for i, query in progress:\n",
    "        dense = eval_dset[\"BAAI/bge-m3\"][i]\n",
    "        indices = eval_dset[\"bm25_indices\"][i]\n",
    "        values = eval_dset[\"bm25_values\"][i]\n",
    "        relevant = eval_dset[\"relevant_articles\"][i]\n",
    "        sparse_vector = SparseVector(indices=indices, values=values)\n",
    "\n",
    "        try:\n",
    "            res = search_with_precomputed_vectors(\n",
    "                client=client,\n",
    "                collection_name=\"bge-laws-2048-chunks\",\n",
    "                top_k=top_k,\n",
    "                retriever_type=mode,\n",
    "                dense_vector=dense,\n",
    "                sparse_vector=sparse_vector,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Search Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            retrieved = []\n",
    "            for r in res.points:\n",
    "                meta = (r.payload or {}).get(\"metadata\", {})\n",
    "                law_code = meta.get(\"law_code\")\n",
    "                law_number = meta.get(\"law_number\")\n",
    "                if law_code and law_number:\n",
    "                    retrieved.append({\n",
    "                        \"law_code\": law_code,\n",
    "                        \"law_number\": law_number\n",
    "                    })\n",
    "            seen = set()\n",
    "            deduped = []\n",
    "            for item in retrieved:\n",
    "                key = (item[\"law_code\"], item[\"law_number\"])\n",
    "                if key not in seen:\n",
    "                    deduped.append(item)\n",
    "                    seen.add(key)\n",
    "            retrieved = deduped\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Parsing Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        if not retrieved:\n",
    "            logger.warning(f\"[Empty Result] Query {i}: {query}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            p, ap, r_, n, recall = compute_metrics(retrieved, relevant, top_k)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Metric Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            top_hit = next(x for x in retrieved if match_article(x, relevant[0]))\n",
    "            hit1 += int(retrieved.index(top_hit) == 0)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"[Hit@1 Index Error] Query {i}: {query}\\n{e}\")\n",
    "\n",
    "        hitk_it = int(p > 0)\n",
    "        hitk += hitk_it\n",
    "        hits.append(hitk_it)\n",
    "        pk.append(p)\n",
    "        mapk.append(ap)\n",
    "        mrr.append(r_)\n",
    "        ndcg.append(n)\n",
    "        recall_values.append(recall)\n",
    "\n",
    "        if hitk_it < recall:\n",
    "            logger.warning(\n",
    "                f\"[Hit@{top_k} Mismatch] Query {i}: Hit@{top_k} < Recall@{top_k}\\n\"\n",
    "                f\"Hit@{top_k}: {hitk_it} | Recall@{top_k}: {recall}\\n\"\n",
    "                f\"Precision@{top_k}: {p}\\n\"\n",
    "                f\"Query: {query}\\n\"\n",
    "                f\"Relevant: {relevant}\\n\"\n",
    "                f\"Retrieved: {retrieved}\"\n",
    "            )\n",
    "\n",
    "        if VERBOSE:\n",
    "            logger.info(\n",
    "                f\"[Query {i}] Mode: {mode} | P@{top_k}: {p:.3f} | R@{top_k}: {recall:.3f} | AP: {ap:.3f} | RR: {r_:.3f} | NDCG: {n:.3f}\"\n",
    "            )\n",
    "\n",
    "        progress.set_description(\n",
    "            f\"{mode} | Hit@{top_k}: {hitk/total:.3f} | Recall@{top_k}: {np.mean(recall_values):.3f}\"\n",
    "        )\n",
    "\n",
    "    results_bge.append({\n",
    "        \"mode\": mode,\n",
    "        \"Hit@1\": round(hit1 / total, 3),\n",
    "        f\"Hit@{top_k}\": round(hitk / total, 3),\n",
    "        f\"MAP@{top_k}\": round(np.mean(mapk), 3),\n",
    "        \"MRR\": round(np.mean(mrr), 3),\n",
    "        f\"NDCG@{top_k}\": round(np.mean(ndcg), 3),\n",
    "        f\"Recall@{top_k}\": round(np.mean(recall_values), 3),\n",
    "        f\"Precision@{top_k}\": round(np.mean(pk), 3),\n",
    "    })\n",
    "\n",
    "mode_results = pd.DataFrame(results_bge)\n",
    "display(mode_results.sort_values(\"MRR\", ascending=False).reset_index(drop=True))\n",
    "mode_results.to_csv(\n",
    "    rf\"C:\\vscode-projects\\legal-rag-project\\eval_results\\retrieval_modes_comparison_at{top_k}.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2cb28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE reranker on mode: dense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dense+rerank | Hit@5: 0.578 | Recall@5: 0.633:  85%|████████▌ | 176/206 [4:07:35<2:14:40, 269.36s/it]2025-04-22 03:07:14,113 - ERROR - retrieval.tools - Exception in: search_with_precomputed_vectors()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_backends\\sync.py\", line 126, in read\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 116, in send_inner\n",
      "    response = self._client.send(request)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\vscode-projects/legal-rag-project\\logger.py\", line 90, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"c:\\vscode-projects/legal-rag-project\\retrieval\\tools.py\", line 105, in search_with_precomputed_vectors\n",
      "    return client.query_points(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\qdrant_client.py\", line 558, in query_points\n",
      "    return self._client.query_points(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\qdrant_remote.py\", line 670, in query_points\n",
      "    query_result = self.http.search_api.query_points(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api\\search_api.py\", line 783, in query_points\n",
      "    return self._build_for_query_points(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api\\search_api.py\", line 181, in _build_for_query_points\n",
      "    return self.api_client.request(\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 89, in request\n",
      "    return self.send(request, type_)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 106, in send\n",
      "    response = self.middleware(request, self.send_inner)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 215, in __call__\n",
      "    return call_next(request)\n",
      "  File \"c:\\vscode-projects\\legal-rag-project\\.venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 118, in send_inner\n",
      "    raise ResponseHandlingException(e)\n",
      "qdrant_client.http.exceptions.ResponseHandlingException: timed out\n",
      "2025-04-22 03:07:15,894 - ERROR - EVALUATE-LAWS - [Search Error] Query 176: Как составить заявление о возмещении морального вреда после ДТП?\n",
      "timed out\n",
      "dense+rerank | Hit@5: 0.680 | Recall@5: 0.617: 100%|██████████| 206/206 [4:51:32<00:00, 84.91s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BGE reranker on mode: hybrid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hybrid+rerank | Hit@5: 0.636 | Recall@5: 0.580: 100%|██████████| 206/206 [4:25:59<00:00, 77.47s/it]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>Hit@1</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense+rerank</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid+rerank</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mode  Hit@1  Hit@5  MAP@5    MRR  NDCG@5  Recall@5  Precision@5\n",
       "0   dense+rerank  0.427  0.680  0.491  0.536   0.534     0.617        0.144\n",
       "1  hybrid+rerank  0.413  0.636  0.468  0.508   0.506     0.580        0.135"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from retrieval import ONNXReranker\n",
    "\n",
    "# Load ONNX-based BGE-M3 reranker\n",
    "top_rerank_k = 10  # number retrieved before rerank\n",
    "reranker = ONNXReranker(\"bge-reranker-v2-m3-onnx-o3-cpu/model.onnx\")\n",
    "# eval_dset = {k: v[:25] for k, v in eval_dset.items()}\n",
    "\n",
    "results_reranked = []\n",
    "modes = [\"dense\", \"hybrid\"]\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"Evaluating BGE reranker on mode: {mode}\")\n",
    "    hit1 = 0\n",
    "    hitk = 0\n",
    "    pk = []\n",
    "    mapk = []\n",
    "    mrr = []\n",
    "    ndcg = []\n",
    "    recall_values = []\n",
    "    hits = []\n",
    "\n",
    "    total = len(eval_dset[\"queries\"])\n",
    "    progress = tqdm(enumerate(eval_dset[\"queries\"]), total=total)\n",
    "\n",
    "    for i, query in progress:\n",
    "        dense = eval_dset[\"BAAI/bge-m3\"][i]\n",
    "        indices = eval_dset[\"bm25_indices\"][i]\n",
    "        values = eval_dset[\"bm25_values\"][i]\n",
    "        relevant = eval_dset[\"relevant_articles\"][i]\n",
    "        sparse_vector = SparseVector(indices=indices, values=values)\n",
    "\n",
    "        try:\n",
    "            res = search_with_precomputed_vectors(\n",
    "                client=client,\n",
    "                collection_name=\"bge-laws-2048-chunks\",\n",
    "                top_k=top_rerank_k,\n",
    "                retriever_type=mode,\n",
    "                dense_vector=dense,\n",
    "                sparse_vector=sparse_vector,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Search Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        # Collect and deduplicate retrieved documents\n",
    "        try:\n",
    "            docs = []\n",
    "            seen = set()\n",
    "            for r in res.points:\n",
    "                payload = r.payload or {}\n",
    "                meta = payload.get(\"metadata\", {})\n",
    "                law_code = meta.get(\"law_code\")\n",
    "                law_number = meta.get(\"law_number\")\n",
    "                text = payload.get(\"text\", \"\")\n",
    "                if law_code and law_number:\n",
    "                    key = (law_code, law_number)\n",
    "                    if key not in seen:\n",
    "                        docs.append({\n",
    "                            \"text\": text,\n",
    "                            \"law_code\": law_code,\n",
    "                            \"law_number\": law_number\n",
    "                        })\n",
    "                        seen.add(key)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Parsing Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        if not docs:\n",
    "            logger.warning(f\"[Empty Result] Query {i}: {query}\")\n",
    "            continue\n",
    "\n",
    "        # Rerank\n",
    "        try:\n",
    "            pairs = [(query, doc[\"text\"]) for doc in docs]\n",
    "            scores = reranker.predict(pairs)\n",
    "            reranked = [doc for doc, _ in sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)][:top_k]\n",
    "            retrieved = [{\"law_code\": doc[\"law_code\"], \"law_number\": doc[\"law_number\"]} for doc in reranked]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Reranking Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        # Metrics\n",
    "        try:\n",
    "            p, ap, r_, n, recall = compute_metrics(retrieved, relevant, top_k)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[Metric Error] Query {i}: {query}\\n{e}\")\n",
    "            continue\n",
    "\n",
    "        # Hit@1 logic\n",
    "        try:\n",
    "            top_hit = next(x for x in retrieved if match_article(x, relevant[0]))\n",
    "            hit1 += int(retrieved.index(top_hit) == 0)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"[Hit@1 Index Error] Query {i}: {query}\\n{e}\")\n",
    "\n",
    "        hitk_it = int(p > 0)\n",
    "        hitk += hitk_it\n",
    "        hits.append(hitk_it)\n",
    "        pk.append(p)\n",
    "        mapk.append(ap)\n",
    "        mrr.append(r_)\n",
    "        ndcg.append(n)\n",
    "        recall_values.append(recall)\n",
    "\n",
    "        if hitk_it < recall:\n",
    "            logger.warning(\n",
    "                f\"[Hit@{top_k} Mismatch] Query {i}: Hit@{top_k} < Recall@{top_k}\\n\"\n",
    "                f\"Hit@{top_k}: {hitk_it} | Recall@{top_k}: {recall}\\n\"\n",
    "                f\"Precision@{top_k}: {p}\\n\"\n",
    "                f\"Query: {query}\\n\"\n",
    "                f\"Relevant: {relevant}\\n\"\n",
    "                f\"Retrieved: {retrieved}\"\n",
    "            )\n",
    "\n",
    "        if VERBOSE:\n",
    "            logger.info(\n",
    "                f\"[Query {i}] Mode: {mode} | P@{top_k}: {p:.3f} | R@{top_k}: {recall:.3f} | AP: {ap:.3f} | RR: {r_:.3f} | NDCG: {n:.3f}\"\n",
    "            )\n",
    "\n",
    "        progress.set_description(\n",
    "            f\"{mode}+rerank | Hit@{top_k}: {hitk/total:.3f} | Recall@{top_k}: {np.mean(recall_values):.3f}\"\n",
    "        )\n",
    "\n",
    "    results_reranked.append({\n",
    "        \"mode\": mode + \"+rerank\",\n",
    "        \"Hit@1\": round(hit1 / total, 3),\n",
    "        f\"Hit@{top_k}\": round(hitk / total, 3),\n",
    "        f\"MAP@{top_k}\": round(np.mean(mapk), 3),\n",
    "        \"MRR\": round(np.mean(mrr), 3),\n",
    "        f\"NDCG@{top_k}\": round(np.mean(ndcg), 3),\n",
    "        f\"Recall@{top_k}\": round(np.mean(recall_values), 3),\n",
    "        f\"Precision@{top_k}\": round(np.mean(pk), 3),\n",
    "    })\n",
    "\n",
    "# Display & save results\n",
    "reranked_df = pd.DataFrame(results_reranked)\n",
    "display(reranked_df.sort_values(\"MRR\", ascending=False).reset_index(drop=True))\n",
    "\n",
    "reranked_df.to_csv(\n",
    "    rf\"C:\\vscode-projects\\legal-rag-project\\eval_results\\reranked_modes_comparison_at{top_k}.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99303f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
